{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUdxUxrZfFd1",
        "outputId": "d4e95311-5a2c-4c56-e3b0-d1e2fa1de0fa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import string\n",
        "import time\n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClIMwjzofNAB"
      },
      "source": [
        "df1=pd.read_json(\"/content/sample_data/Sarcasm_Headlines_Dataset_v2.json\",lines=True)\n",
        "df1=df1[['headline','is_sarcastic']]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNMHxqocGZRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff4f865-e4f1-4632-dab3-cefbc438ce05"
      },
      "source": [
        "df1.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28619 entries, 0 to 28618\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   headline      28619 non-null  object\n",
            " 1   is_sarcastic  28619 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 447.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ5wgH1YfhYW"
      },
      "source": [
        "df=df1.drop(df1[df1['is_sarcastic']==1].sample(frac=0.10).index)\n",
        "df=df.reset_index()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my5P86PtgKTi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "09eaae1e-1f90-4052-9064-722e7d86be0c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                           headline  is_sarcastic\n",
              "0      0  thirtysomething scientists unveil doomsday clo...             1\n",
              "1      1  dem rep. totally nails why congress is falling...             0\n",
              "2      2  eat your veggies: 9 deliciously different recipes             0\n",
              "3      3  inclement weather prevents liar from getting t...             1\n",
              "4      4  mother comes pretty close to using word 'strea...             1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb7a0e3e-4e4b-407b-8d9e-c67add464065\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb7a0e3e-4e4b-407b-8d9e-c67add464065')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb7a0e3e-4e4b-407b-8d9e-c67add464065 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb7a0e3e-4e4b-407b-8d9e-c67add464065');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3e0adc73-b1e7-4b56-b796-b79b80a22739\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3e0adc73-b1e7-4b56-b796-b79b80a22739')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3e0adc73-b1e7-4b56-b796-b79b80a22739 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4kFd_b7Rxs2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ec8cd8-4d81-4fa1-d6d8-f57999768483"
      },
      "source": [
        "df.index"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RangeIndex(start=0, stop=27256, step=1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBZMuIc7gjLt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "48da250f-5e01-4e86-bbb6-5b35c9f4f9e8"
      },
      "source": [
        "sns.countplot(data=df,x=df.is_sarcastic);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_CvcBISgzN5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "7e289d1a-2ca6-4a2f-c527-5223eba12d72"
      },
      "source": [
        "pd.options.display.max_colwidth = 200\n",
        "pd.DataFrame(df[df['is_sarcastic']==1]['headline']).head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                    headline\n",
              "0                                              thirtysomething scientists unveil doomsday clock of hair loss\n",
              "3                                                       inclement weather prevents liar from getting to work\n",
              "4                                              mother comes pretty close to using word 'streaming' correctly\n",
              "7                                  shadow government getting too large to meet in marriott conference room b\n",
              "13                                                        ford develops new suv that runs purely on gasoline\n",
              "15                                               area boy enters jumping-and-touching-tops-of-doorways phase\n",
              "16                                                             area man does most of his traveling by gurney\n",
              "20                        guard in video game under strict orders to repeatedly pace same stretch of hallway\n",
              "31                                           new york introduces shoe-sharing program for city's pedestrians\n",
              "33  expansive obama state of the union speech to touch on patent law, entomology, the films of robert altman"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ddca39d-8346-4631-9ba5-50fd5a727d40\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thirtysomething scientists unveil doomsday clock of hair loss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>inclement weather prevents liar from getting to work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mother comes pretty close to using word 'streaming' correctly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>shadow government getting too large to meet in marriott conference room b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ford develops new suv that runs purely on gasoline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>area boy enters jumping-and-touching-tops-of-doorways phase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>area man does most of his traveling by gurney</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>guard in video game under strict orders to repeatedly pace same stretch of hallway</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>new york introduces shoe-sharing program for city's pedestrians</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>expansive obama state of the union speech to touch on patent law, entomology, the films of robert altman</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ddca39d-8346-4631-9ba5-50fd5a727d40')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ddca39d-8346-4631-9ba5-50fd5a727d40 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ddca39d-8346-4631-9ba5-50fd5a727d40');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c0d8e8e9-eb94-42b7-9582-3e63f62041d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0d8e8e9-eb94-42b7-9582-3e63f62041d6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c0d8e8e9-eb94-42b7-9582-3e63f62041d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXkEji5-goO1"
      },
      "source": [
        "def decontract(text):\n",
        "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s$\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    return text\n",
        "stopwords_english = set(stopwords.words('english'))-set(['No','no','not','Not'])\n",
        "def preprocess(text,stopwords=stopwords_english):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "    # remove stock market tickers like $GE\n",
        "    text = re.sub(r'\\$\\w*', '', text)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    text = re.sub(r'^RT[\\s]+', '', text)\n",
        "    # remove hyperlinks\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "    #Decontract texts\n",
        "    text=decontract(text)\n",
        "    # tokenize texts\n",
        "\n",
        "\n",
        "    texts_clean = []\n",
        "    for word in text.split():\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in set(string.punctuation)-set(['!','?','.','@',':'])):  # remove punctuation\n",
        "            #Lemmatize word\n",
        "            lem_word = lemmatizer.lemmatize(word,\"v\")  # Lemmatizing word\n",
        "            texts_clean.append(lem_word)\n",
        "\n",
        "    return \" \".join(texts_clean)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv7RuniYg4tq"
      },
      "source": [
        "inputs=list(df['headline'].apply(lambda x: preprocess(x)))\n",
        "labels=list(df['is_sarcastic'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.2)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccGOGVKiSX-h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "21829f59-d4e1-4fb5-e2ef-beee8307860a"
      },
      "source": [
        "sns.countplot(x=y_train);"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8QV4WoIg-Jz"
      },
      "source": [
        "def subword_tokenize(train_corpus, vocab_size=2**14, max_length=50,tokenizer=None):\n",
        "  # Create the vocabulary using Subword tokenization\n",
        "  if(tokenizer==None):\n",
        "    tokenizer_corpus = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(train_corpus, target_vocab_size=2**14)\n",
        "  else:\n",
        "    tokenizer_corpus=tokenizer\n",
        "  # Get the final vocab size, adding the eos and sos tokens\n",
        "  vocab_size = tokenizer_corpus.vocab_size\n",
        "\n",
        "  # Tokenize the corpus\n",
        "  sentences = [tokenizer_corpus.encode(sentence) for sentence in train_corpus]\n",
        "\n",
        "  #Pad the sentences\n",
        "  sentences = tf.keras.preprocessing.sequence.pad_sequences(sentences,value=0,padding='post',maxlen=50)\n",
        "\n",
        "  return sentences, tokenizer_corpus, vocab_size"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG68lIkzg-pR"
      },
      "source": [
        "tokenized_inputs,tokenizer,vocab_size=subword_tokenize(train_corpus=X_train)\n",
        "tokenized_test_inputs,_,vocab_size2=subword_tokenize(X_test,tokenizer=tokenizer)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q75qmBWchB0-"
      },
      "source": [
        "# Define a dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((tokenized_inputs, y_train))\n",
        "dataset = dataset.shuffle(len(tokenized_inputs), reshuffle_each_iteration=True).batch(128, drop_remainder=True)\n",
        "\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rO9uxMvhJKZ"
      },
      "source": [
        "def scaled_dot_product_attention(queries, keys, values, mask):\n",
        "    # Calculate the dot product, QK_transpose\n",
        "    product = tf.matmul(queries, keys, transpose_b=True)\n",
        "    # Get the scale factor\n",
        "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
        "    # Apply the scale factor to the dot product\n",
        "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
        "    # Apply masking when it is requiered\n",
        "    if mask is not None:\n",
        "        scaled_product += (mask * -1e9)\n",
        "    # dot product with Values\n",
        "    attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n",
        "\n",
        "    return attention"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zz6kUnBhKy2"
      },
      "source": [
        "class MultiHeadAttention(layers.Layer):\n",
        "\n",
        "    def __init__(self, n_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "        assert self.d_model % self.n_heads == 0\n",
        "        # Calculate the dimension of every head or projection\n",
        "        self.d_head = self.d_model // self.n_heads\n",
        "        # Set the weight matrices for Q, K and V\n",
        "        self.query_lin = layers.Dense(units=self.d_model)\n",
        "        self.key_lin = layers.Dense(units=self.d_model)\n",
        "        self.value_lin = layers.Dense(units=self.d_model)\n",
        "        # Set the weight matrix for the output of the multi-head attention W0\n",
        "        self.final_lin = layers.Dense(units=self.d_model)\n",
        "\n",
        "    def split_proj(self, inputs, batch_size): # inputs: (batch_size, seq_length, d_model)\n",
        "        # Set the dimension of the projections\n",
        "        shape = (batch_size,\n",
        "                 -1,\n",
        "                 self.n_heads,\n",
        "                 self.d_head)\n",
        "        # Split the input vectors\n",
        "        splited_inputs = tf.reshape(inputs, shape=shape) # (batch_size, seq_length, nb_proj, d_proj)\n",
        "        return tf.transpose(splited_inputs, perm=[0, 2, 1, 3]) # (batch_size, nb_proj, seq_length, d_proj)\n",
        "\n",
        "    def call(self, queries, keys, values, mask):\n",
        "        # Get the batch size\n",
        "        batch_size = tf.shape(queries)[0]\n",
        "        # Set the Query, Key and Value matrices\n",
        "        queries = self.query_lin(queries)\n",
        "        keys = self.key_lin(keys)\n",
        "        values = self.value_lin(values)\n",
        "        # Split Q, K y V between the heads or projections\n",
        "        queries = self.split_proj(queries, batch_size)\n",
        "        keys = self.split_proj(keys, batch_size)\n",
        "        values = self.split_proj(values, batch_size)\n",
        "        # Apply the scaled dot product\n",
        "        attention = scaled_dot_product_attention(queries, keys, values, mask)\n",
        "        # Get the attention scores\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        # Concat the h heads or projections\n",
        "        concat_attention = tf.reshape(attention,\n",
        "                                      shape=(batch_size, -1, self.d_model))\n",
        "        # Apply W0 to get the output of the multi-head attention\n",
        "        outputs = self.final_lin(concat_attention)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeauD4UhhLRQ"
      },
      "source": [
        "class PositionalEncoding(layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "    def get_angles(self, pos, i, d_model): # pos: (seq_length, 1) i: (1, d_model)\n",
        "        angles = 1 / np.power(10000., (2*(i//2)) / np.float32(d_model))\n",
        "        return pos * angles # (seq_length, d_model)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # input shape batch_size, seq_length, d_model\n",
        "        seq_length = inputs.shape.as_list()[-2]\n",
        "        d_model = inputs.shape.as_list()[-1]\n",
        "        # Calculate the angles given the input\n",
        "        angles = self.get_angles(np.arange(seq_length)[:, np.newaxis],\n",
        "                                 np.arange(d_model)[np.newaxis, :],\n",
        "                                 d_model)\n",
        "        # Calculate the positional encodings\n",
        "        angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
        "        angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
        "        # Expand the encodings with a new dimension\n",
        "        pos_encoding = angles[np.newaxis, ...]\n",
        "\n",
        "        return inputs + tf.cast(pos_encoding, tf.float32)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMz_apUHhMzF"
      },
      "source": [
        "class EncoderLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, FFN_units, n_heads, dropout_rate):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        # Hidden units of the feed forward component\n",
        "        self.FFN_units = FFN_units\n",
        "        # Set the number of projectios or heads\n",
        "        self.n_heads = n_heads\n",
        "        # Dropout rate\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "        # Build the multihead layer\n",
        "        self.multi_head_attention = MultiHeadAttention(self.n_heads)\n",
        "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
        "        # Layer Normalization\n",
        "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        # Fully connected feed forward layer\n",
        "        self.ffn1_relu = layers.Dense(units=self.FFN_units, activation=\"relu\")\n",
        "        self.ffn2 = layers.Dense(units=self.d_model)\n",
        "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
        "        # Layer normalization\n",
        "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs, mask, training):\n",
        "        # Forward pass of the multi-head attention\n",
        "        attention = self.multi_head_attention(inputs,\n",
        "                                              inputs,\n",
        "                                              inputs,\n",
        "                                              mask)\n",
        "        attention = self.dropout_1(attention, training=training)\n",
        "        # Call to the residual connection and layer normalization\n",
        "        attention = self.norm_1(attention + inputs)\n",
        "        # Call to the FC layer\n",
        "        outputs = self.ffn1_relu(attention)\n",
        "        outputs = self.ffn2(outputs)\n",
        "        outputs = self.dropout_2(outputs, training=training)\n",
        "        # Call to residual connection and the layer normalization\n",
        "        outputs = self.norm_2(outputs + attention)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANHZDbGchOxO"
      },
      "source": [
        "class Encoder(layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 FFN_units,\n",
        "                 n_heads,\n",
        "                 dropout_rate,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"encoder\"):\n",
        "        super(Encoder, self).__init__(name=name)\n",
        "        self.n_layers = n_layers\n",
        "        self.d_model = d_model\n",
        "        # The embedding layer\n",
        "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "        # Positional encoding layer\n",
        "        self.pos_encoding = PositionalEncoding()\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        # Stack of n layers of multi-head attention and FC\n",
        "        self.enc_layers = [EncoderLayer(FFN_units,\n",
        "                                        n_heads,\n",
        "                                        dropout_rate)\n",
        "                           for _ in range(n_layers)]\n",
        "        self.last_linear = layers.Dense(units=2, name=\"lin_ouput\")\n",
        "\n",
        "    def call(self, inputs, mask, training):\n",
        "        # Get the embedding vectors\n",
        "        outputs = self.embedding(inputs)\n",
        "        # Scale the embeddings by sqrt of d_model\n",
        "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        # Positional encodding\n",
        "        outputs = self.pos_encoding(outputs)\n",
        "        outputs = self.dropout(outputs, training)\n",
        "        # Call the stacked layers\n",
        "        for i in range(self.n_layers):\n",
        "            outputs = self.enc_layers[i](outputs, mask, training)\n",
        "\n",
        "        logits=tf.math.reduce_mean(outputs,1)\n",
        "        #print(logits.shape)\n",
        "\n",
        "\n",
        "        logits=self.last_linear(logits)\n",
        "\n",
        "        return logits #outputs[:,0:1,:]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0klrzE7hSe_"
      },
      "source": [
        "def create_padding_mask(seq): #seq: (batch_size, seq_length)\n",
        "# Create the mask for padding\n",
        "  mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "def loss_function(target, pred):\n",
        "\n",
        "\n",
        "    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(target,pred)\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)  # 将步骤数显式转换为浮点数类型\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbe83tAAhTHL"
      },
      "source": [
        "def main_train(dataset, encoder, n_epochs, print_every=50):\n",
        "  ''' Train the transformer model for n_epochs using the data generator dataset'''\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  # In every epoch\n",
        "  for epoch in range(n_epochs):\n",
        "    print(\"Starting epoch {}\".format(epoch+1))\n",
        "    start = time.time()\n",
        "    # Reset the losss and accuracy calculations\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    # Get a batch of inputs and targets\n",
        "    for (batch, (inputs, targets)) in enumerate(dataset):\n",
        "        # Set the decoder inputs\n",
        "        #dec_inputs = targets[:, :-1]\n",
        "        # Set the target outputs, right shifted\n",
        "        targets = pd.get_dummies(targets).astype('float').values\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Call the transformer and get the predicted output\n",
        "            predictions = encoder(inputs, create_padding_mask(inputs), True)\n",
        "            # Calculate the loss\n",
        "            loss = loss_function(targets, predictions)\n",
        "        # Update the weights and optimizer\n",
        "        gradients = tape.gradient(loss, encoder.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, encoder.trainable_variables))\n",
        "        # Save and store the metrics\n",
        "        train_loss(loss)\n",
        "\n",
        "        train_accuracy(targets, predictions)\n",
        "\n",
        "        if batch % print_every == 0:\n",
        "            losses.append(train_loss.result())\n",
        "            accuracies.append(train_accuracy.result())\n",
        "            print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(\n",
        "                epoch+1, batch, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "    # Checkpoint the model on every epoch\n",
        "    #ckpt_save_path = ckpt_manager.save()\n",
        "    #print(\"Saving checkpoint for epoch {} in {}\".format(epoch+1,ckpt_save_path))\n",
        "    #print(\"Time for 1 epoch: {} secs\\n\".format(time.time() - start))\n",
        "\n",
        "  return losses, accuracies"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpzNg_vVhUkU"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "# Create the Encoder model\n",
        "encoder = Encoder(6,512,8,0.1,vocab_size,256)\n",
        "\n",
        "\n",
        "# Define a metric to store the mean loss of every epoch\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "# Define a matric to save the accuracy in every epoch\n",
        "train_accuracy = tf.keras.metrics.BinaryAccuracy(name=\"train_accuracy\")\n",
        "# Create the scheduler for learning rate decay\n",
        "leaning_rate = CustomSchedule(256)\n",
        "\n",
        "# Create the Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(leaning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXP_yE2XhWHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f654cb06-9a55-4e08-a562-f00d56ac203b"
      },
      "source": [
        "losses, accuracies = main_train(dataset, encoder, 5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7828358740d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7828358740d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 0.7681 Accuracy 0.4961\n",
            "Epoch 1 Batch 50 Loss 0.7091 Accuracy 0.5105\n",
            "Epoch 1 Batch 100 Loss 0.6891 Accuracy 0.5299\n",
            "Epoch 1 Batch 150 Loss 0.6793 Accuracy 0.5450\n",
            "Starting epoch 2\n",
            "Epoch 2 Batch 0 Loss 0.6056 Accuracy 0.6367\n",
            "Epoch 2 Batch 50 Loss 0.5921 Accuracy 0.6646\n",
            "Epoch 2 Batch 100 Loss 0.5852 Accuracy 0.6708\n",
            "Epoch 2 Batch 150 Loss 0.5617 Accuracy 0.6907\n",
            "Starting epoch 3\n",
            "Epoch 3 Batch 0 Loss 0.4576 Accuracy 0.7930\n",
            "Epoch 3 Batch 50 Loss 0.4342 Accuracy 0.7916\n",
            "Epoch 3 Batch 100 Loss 0.4268 Accuracy 0.7943\n",
            "Epoch 3 Batch 150 Loss 0.4160 Accuracy 0.7999\n",
            "Starting epoch 4\n",
            "Epoch 4 Batch 0 Loss 0.3196 Accuracy 0.8555\n",
            "Epoch 4 Batch 50 Loss 0.3293 Accuracy 0.8536\n",
            "Epoch 4 Batch 100 Loss 0.3107 Accuracy 0.8608\n",
            "Epoch 4 Batch 150 Loss 0.3150 Accuracy 0.8585\n",
            "Starting epoch 5\n",
            "Epoch 5 Batch 0 Loss 0.1868 Accuracy 0.9414\n",
            "Epoch 5 Batch 50 Loss 0.2114 Accuracy 0.9127\n",
            "Epoch 5 Batch 100 Loss 0.2132 Accuracy 0.9115\n",
            "Epoch 5 Batch 150 Loss 0.2241 Accuracy 0.9058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "437OfKxAh22Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "639e29bb-d7d7-4873-b787-ac12a1fba18d"
      },
      "source": [
        "def predict(encoder,tokenized_sentences):\n",
        "  logits=encoder(tokenized_sentences,create_padding_mask(tokenized_sentences),False)\n",
        "  predictions=np.argmax(tf.keras.layers.Softmax()(logits),axis=1)\n",
        "  return predictions\n",
        "test_accuracy=sum((predict(encoder,tokenized_test_inputs)==y_test))\n",
        "test_accuracy/=len(y_test)\n",
        "print(test_accuracy)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(predict(encoder,tokenized_test_inputs),y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.811995597945708\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83      3126\n",
            "           1       0.76      0.81      0.79      2326\n",
            "\n",
            "    accuracy                           0.81      5452\n",
            "   macro avg       0.81      0.81      0.81      5452\n",
            "weighted avg       0.81      0.81      0.81      5452\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05xL9XMEU_w2"
      },
      "source": [],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llGjigt7iqMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404d46d2-feab-4162-fe91-47e14e4fa985"
      },
      "source": [
        "class Encoder(layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 FFN_units,\n",
        "                 n_heads,\n",
        "                 dropout_rate,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"encoder_lstm\"):\n",
        "        super(Encoder, self).__init__(name=name)\n",
        "        self.n_layers = n_layers\n",
        "        self.d_model = d_model\n",
        "        # The embedding layer\n",
        "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "        # Positional encoding layer\n",
        "        self.pos_encoding = PositionalEncoding()\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        # Stack of n layers of multi-head attention and FC\n",
        "        self.enc_layers = [EncoderLayer(FFN_units,\n",
        "                                        n_heads,\n",
        "                                        dropout_rate)\n",
        "                           for _ in range(n_layers)]\n",
        "        self.lstm=layers.LSTM(128)\n",
        "        self.last_linear = layers.Dense(units=2, name=\"lin_ouput\")\n",
        "\n",
        "    def call(self, inputs, mask, training):\n",
        "        # Get the embedding vectors\n",
        "        outputs = self.embedding(inputs)\n",
        "        # Scale the embeddings by sqrt of d_model\n",
        "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        # Positional encodding\n",
        "        outputs = self.pos_encoding(outputs)\n",
        "        outputs = self.dropout(outputs, training)\n",
        "        # Call the stacked layers\n",
        "        for i in range(self.n_layers):\n",
        "            outputs = self.enc_layers[i](outputs, mask, training)\n",
        "\n",
        "        #logits=tf.math.reduce_mean(outputs,1)\n",
        "        #print(logits.shape)\n",
        "        logits=self.lstm(outputs)\n",
        "\n",
        "\n",
        "        logits=self.last_linear(logits)\n",
        "\n",
        "        return logits #outputs[:,0:1,:]\n",
        "\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "# Create the Encoder model\n",
        "encoder_lstm = Encoder(6,512,8,0.1,vocab_size,256)\n",
        "\n",
        "\n",
        "# Define a metric to store the mean loss of every epoch\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "# Define a matric to save the accuracy in every epoch\n",
        "train_accuracy = tf.keras.metrics.BinaryAccuracy(name=\"train_accuracy\")\n",
        "# Create the scheduler for learning rate decay\n",
        "leaning_rate = CustomSchedule(256)\n",
        "# Create the Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(leaning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "losses, accuracies = main_train(dataset, encoder_lstm, 5)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "Epoch 1 Batch 0 Loss 0.6813 Accuracy 0.5039\n",
            "Epoch 1 Batch 50 Loss 0.6922 Accuracy 0.5063\n",
            "Epoch 1 Batch 100 Loss 0.6877 Accuracy 0.5118\n",
            "Epoch 1 Batch 150 Loss 0.6793 Accuracy 0.5273\n",
            "Starting epoch 2\n",
            "Epoch 2 Batch 0 Loss 0.6602 Accuracy 0.6250\n",
            "Epoch 2 Batch 50 Loss 0.6147 Accuracy 0.6419\n",
            "Epoch 2 Batch 100 Loss 0.5874 Accuracy 0.6686\n",
            "Epoch 2 Batch 150 Loss 0.5719 Accuracy 0.6824\n",
            "Starting epoch 3\n",
            "Epoch 3 Batch 0 Loss 0.4393 Accuracy 0.7891\n",
            "Epoch 3 Batch 50 Loss 0.4272 Accuracy 0.7966\n",
            "Epoch 3 Batch 100 Loss 0.4210 Accuracy 0.7977\n",
            "Epoch 3 Batch 150 Loss 0.4164 Accuracy 0.8006\n",
            "Starting epoch 4\n",
            "Epoch 4 Batch 0 Loss 0.2495 Accuracy 0.8984\n",
            "Epoch 4 Batch 50 Loss 0.2949 Accuracy 0.8730\n",
            "Epoch 4 Batch 100 Loss 0.3066 Accuracy 0.8651\n",
            "Epoch 4 Batch 150 Loss 0.3120 Accuracy 0.8619\n",
            "Starting epoch 5\n",
            "Epoch 5 Batch 0 Loss 0.2681 Accuracy 0.8711\n",
            "Epoch 5 Batch 50 Loss 0.2262 Accuracy 0.9054\n",
            "Epoch 5 Batch 100 Loss 0.2300 Accuracy 0.9030\n",
            "Epoch 5 Batch 150 Loss 0.2349 Accuracy 0.9018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHpkyrDOizPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a359a11-5114-413f-a208-d535cc4da6cb"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(predict(encoder_lstm,tokenized_test_inputs),y_test))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82      2757\n",
            "           1       0.83      0.76      0.80      2695\n",
            "\n",
            "    accuracy                           0.81      5452\n",
            "   macro avg       0.81      0.81      0.81      5452\n",
            "weighted avg       0.81      0.81      0.81      5452\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8ZM4cHPi1FN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1088f94-3036-48cc-c139-4ea0a3f787ec"
      },
      "source": [
        "class Encoder(layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 FFN_units,\n",
        "                 n_heads,\n",
        "                 dropout_rate,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"encoder_cnn\"):\n",
        "        super(Encoder, self).__init__(name=name)\n",
        "        self.n_layers = n_layers\n",
        "        self.d_model = d_model\n",
        "        # The embedding layer\n",
        "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "        # Positional encoding layer\n",
        "        self.pos_encoding = PositionalEncoding()\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        # Stack of n layers of multi-head attention and FC\n",
        "        self.enc_layers = [EncoderLayer(FFN_units,\n",
        "                                        n_heads,\n",
        "                                        dropout_rate)\n",
        "                           for _ in range(n_layers)]\n",
        "        self.cnn=layers.Conv2D(1, (3,3), activation='relu', padding='same', input_shape=(50,256,1))\n",
        "        self.flatten=layers.Flatten()\n",
        "        self.last_linear = layers.Dense(units=2, name=\"lin_ouput\")\n",
        "\n",
        "    def call(self, inputs, mask, training):\n",
        "        # Get the embedding vectors\n",
        "        outputs = self.embedding(inputs)\n",
        "        # Scale the embeddings by sqrt of d_model\n",
        "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        # Positional encodding\n",
        "        outputs = self.pos_encoding(outputs)\n",
        "        outputs = self.dropout(outputs, training)\n",
        "        # Call the stacked layers\n",
        "        for i in range(self.n_layers):\n",
        "            outputs = self.enc_layers[i](outputs, mask, training)\n",
        "\n",
        "        #logits=tf.math.reduce_mean(outputs,1)\n",
        "        #print(logits.shape)\n",
        "        logits=K.expand_dims(outputs,axis=-1)\n",
        "        logits=self.cnn(logits)\n",
        "        logits=self.flatten(logits)\n",
        "\n",
        "\n",
        "        logits=self.last_linear(logits)\n",
        "\n",
        "        return logits #outputs[:,0:1,:]\n",
        "tf.keras.backend.clear_session()\n",
        "# Create the Encoder model\n",
        "encoder_cnn = Encoder(6,512,8,0.1,vocab_size,256)\n",
        "\n",
        "\n",
        "# Define a metric to store the mean loss of every epoch\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "# Define a matric to save the accuracy in every epoch\n",
        "train_accuracy = tf.keras.metrics.BinaryAccuracy(name=\"train_accuracy\")\n",
        "# Create the scheduler for learning rate decay\n",
        "leaning_rate = CustomSchedule(256)\n",
        "# Create the Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(leaning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n",
        "losses, accuracies = main_train(dataset, encoder_cnn, 4)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "Epoch 1 Batch 0 Loss 0.7390 Accuracy 0.4922\n",
            "Epoch 1 Batch 50 Loss 0.7129 Accuracy 0.5077\n",
            "Epoch 1 Batch 100 Loss 0.7040 Accuracy 0.5140\n",
            "Epoch 1 Batch 150 Loss 0.6951 Accuracy 0.5253\n",
            "Starting epoch 2\n",
            "Epoch 2 Batch 0 Loss 0.6226 Accuracy 0.6367\n",
            "Epoch 2 Batch 50 Loss 0.6274 Accuracy 0.6388\n",
            "Epoch 2 Batch 100 Loss 0.6017 Accuracy 0.6617\n",
            "Epoch 2 Batch 150 Loss 0.5830 Accuracy 0.6775\n",
            "Starting epoch 3\n",
            "Epoch 3 Batch 0 Loss 0.5123 Accuracy 0.7383\n",
            "Epoch 3 Batch 50 Loss 0.4476 Accuracy 0.7845\n",
            "Epoch 3 Batch 100 Loss 0.4333 Accuracy 0.7930\n",
            "Epoch 3 Batch 150 Loss 0.4258 Accuracy 0.7970\n",
            "Starting epoch 4\n",
            "Epoch 4 Batch 0 Loss 0.3015 Accuracy 0.8750\n",
            "Epoch 4 Batch 50 Loss 0.3021 Accuracy 0.8693\n",
            "Epoch 4 Batch 100 Loss 0.3068 Accuracy 0.8642\n",
            "Epoch 4 Batch 150 Loss 0.3055 Accuracy 0.8640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlfAL00cXDaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cca1419-e01a-47b7-cedd-54ac1d36fa11"
      },
      "source": [
        "losses, accuracies = main_train(dataset, encoder_cnn, 1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "Epoch 1 Batch 0 Loss 0.2268 Accuracy 0.8750\n",
            "Epoch 1 Batch 50 Loss 0.2248 Accuracy 0.9038\n",
            "Epoch 1 Batch 100 Loss 0.2370 Accuracy 0.9002\n",
            "Epoch 1 Batch 150 Loss 0.2348 Accuracy 0.9021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tnz7Liti81f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8319faf2-0759-402b-d01e-b8f03f4e2d5f"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(predict(encoder_cnn,tokenized_test_inputs),y_test))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.79      0.83      3258\n",
            "           1       0.73      0.82      0.77      2194\n",
            "\n",
            "    accuracy                           0.81      5452\n",
            "   macro avg       0.80      0.81      0.80      5452\n",
            "weighted avg       0.81      0.81      0.81      5452\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBcVobkEibPd"
      },
      "source": [
        "examples=['Woman wins award for safe driving','I work forty hours a week for me to be this poor.','I would kill for a Nobel Peace Prize.','Depression is merely anger without enthusiasm.','Two wrongs don’t make a right take your parents as an example .','If I wanted to kill myself I’d climb your ego and jump to your IQ.','Always remember that you are absolutely unique just like everyone else .','Congratulations, If you press the elevator button three times it goes into hurry mode – really...','Hello my name is Raj and I study computer science!','Please get me some fruits from the store .','Want to hang out today ?','Presidency is probably the toughest job around','We should go out and play football','Discounted items end up being the most expensive']"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH02cwjhYysh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed80c74b-bc6e-43aa-8aff-c6e749aa7df4"
      },
      "source": [
        "example=\"Trump's tenure oversaw a massive economic decline , definitely going to vote for him again .\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(encoder,sentence))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trump's tenure oversaw a massive economic decline , definitely going to vote for him again .\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_18yuLw2Za4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2d5747-113b-4930-c555-cf0151ce69e6"
      },
      "source": [
        "example=\"Today is such a beautiful day , the weather is perfect to stay inside .\"\n",
        "sentence=tokenizer.encode(preprocess(example))\n",
        "sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "print(example)\n",
        "print(predict(encoder,sentence))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today is such a beautiful day , the weather is perfect to stay inside .\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU7Ho0bZigy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0af76a-7615-4899-f33a-a8c5f939952f"
      },
      "source": [
        "#example='Woman wins award for safe driving'\n",
        "for example in examples:\n",
        "  sentence=tokenizer.encode(preprocess(example))\n",
        "  sentence=tf.keras.preprocessing.sequence.pad_sequences([sentence],value=0,padding='post',maxlen=50)\n",
        "  print(example)\n",
        "  print(predict(encoder,sentence))\n",
        "  print(predict(encoder_lstm,sentence))\n",
        "  print(predict(encoder_cnn,sentence))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Woman wins award for safe driving\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "I work forty hours a week for me to be this poor.\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "I would kill for a Nobel Peace Prize.\n",
            "[1]\n",
            "[1]\n",
            "[0]\n",
            "Depression is merely anger without enthusiasm.\n",
            "[0]\n",
            "[1]\n",
            "[1]\n",
            "Two wrongs don’t make a right take your parents as an example .\n",
            "[0]\n",
            "[0]\n",
            "[1]\n",
            "If I wanted to kill myself I’d climb your ego and jump to your IQ.\n",
            "[0]\n",
            "[1]\n",
            "[0]\n",
            "Always remember that you are absolutely unique just like everyone else .\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "Congratulations, If you press the elevator button three times it goes into hurry mode – really...\n",
            "[1]\n",
            "[1]\n",
            "[0]\n",
            "Hello my name is Raj and I study computer science!\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "Please get me some fruits from the store .\n",
            "[0]\n",
            "[0]\n",
            "[1]\n",
            "Want to hang out today ?\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "Presidency is probably the toughest job around\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "We should go out and play football\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "Discounted items end up being the most expensive\n",
            "[1]\n",
            "[1]\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_1Q5NzJmzlC"
      },
      "source": [
        "import os\n",
        "checkpoint_folder = \"ckpt/\"\n",
        "checkpoint_path = os.path.abspath(os.path.join('', checkpoint_folder))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Is0T27op16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "889ddfcf-5600-460e-a08f-cd5c1a291daf"
      },
      "source": [
        "checkpoint_path"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzBgZdwspELU"
      },
      "source": [
        "ckpt = tf.train.Checkpoint(encoder=encoder,optimizer=optimizer,)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Last checkpoint restored.\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi9jpLzhpINS"
      },
      "source": [
        "ckpt_save_path = ckpt_manager.save()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxDWJtwjpT8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faaecb5d-9f61-4a6b-9d6a-041e8c583c61"
      },
      "source": [
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Last checkpoint restored.\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last checkpoint restored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dOh2YbEamx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb431fe-fa3e-459a-8c8a-99d7605cc663"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "def predict_proba2(encoder,examples):\n",
        "    #sentences=[tokenizer.encode(example) for example in examples]\n",
        "    #sentences=tf.keras.preprocessing.sequence.pad_sequences(sentences,value=0,padding='post',maxlen=50)\n",
        "    logits=encoder(examples,create_padding_mask(examples),False)\n",
        "    return layers.Softmax()(logits).numpy()\n",
        "\n",
        "print(roc_auc_score(y_test, predict_proba2(encoder,tokenized_test_inputs)[:, 1]))\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8949211402583959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89M760EAqGiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2384dd4f-1b65-4404-8f50-5522af5d40c7"
      },
      "source": [
        "\n",
        "print(roc_auc_score(y_test, predict_proba2(encoder,tokenized_test_inputs)[:, 1]))\n",
        "print(roc_auc_score(y_test, predict_proba2(encoder_lstm,tokenized_test_inputs)[:, 1]))\n",
        "print(roc_auc_score(y_test, predict_proba2(encoder_cnn,tokenized_test_inputs)[:, 1]))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8949211402583959\n",
            "0.8982466156477198\n",
            "0.8920512735936839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKyntIjrtJLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a338cf51-f368-46dd-8f7d-9ad09b6f5d04"
      },
      "source": [
        "print(roc_auc_score(y_test, predict_proba2(encoder_cnn,tokenized_test_inputs)[:, 1]))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8920512735936839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I08LPJwaybQ"
      },
      "source": [
        "encoder=Encoder()"
      ],
      "execution_count": 51,
      "outputs": []
    }
  ]
}